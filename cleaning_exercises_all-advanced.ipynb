{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning: Cycle Share\n",
    "\n",
    "There are 3 datasets that provide data on the stations, trips, and weather from 2014-2016.\n",
    "\n",
    "**Station dataset**\n",
    "\n",
    "* station_id: station ID number\n",
    "* name: name of station\n",
    "* lat: station latitude\n",
    "* long: station longitude\n",
    "* install_date: date that station was placed in service\n",
    "* install_dockcount: number of docks at each station on the installation date\n",
    "* modification_date: date that station was modified, resulting in a change in location or dock count\n",
    "* current_dockcount: number of docks at each station on 8/31/2016\n",
    "* decommission_date: date that station was placed out of service\n",
    "\n",
    "**Trip dataset**\n",
    "\n",
    "* trip_id: numeric ID of bike trip taken\n",
    "* starttime: day and time trip started, in PST\n",
    "* stoptime: day and time trip ended, in PST\n",
    "* bikeid: ID attached to each bike\n",
    "* tripduration: time of trip in seconds\n",
    "* from_station_name: name of station where trip originated\n",
    "* to_station_name: name of station where trip terminated\n",
    "* from_station_id: ID of station where trip originated\n",
    "* to_station_id: ID of station where trip terminated\n",
    "* usertype: \"Short-Term Pass Holder\" is a rider who purchased a 24-Hour or 3-Day Pass; \"Member\" is a rider who purchased a Monthly or an Annual Membership\n",
    "* gender: gender of rider\n",
    "* birthyear: birth year of rider\n",
    "\n",
    "**Weather dataset** contains daily weather information in the service area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import all sets into a dictionary and correct any errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series\n",
    "from pandas import DataFrame as DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File : trip.csv\n",
      "\n",
      "Error tokenizing data. C error: Expected 12 fields in line 50794, saw 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "files = listdir('cycle_share')\n",
    "data = {}\n",
    "\n",
    "for f in files:\n",
    "    k = f.split('.')[0]\n",
    "    path = 'cycle_share/' + f\n",
    "    try:\n",
    "        data[k] = pd.read_csv(path)\n",
    "    except Exception as e:\n",
    "        print('File : {}\\n'.format(f))\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59000,\"4/17/2015 14:21\",\"4/17/2015 19:21\",\"SEA00362\",17990.668,\"6th Ave S & S King St\",\"Westlake Ave & 6th Ave\",\"ID-04\",\"SLU-15\"trip_id\",\"starttime\",\"stoptime\",\"bikeid\",\"tripduration\",\"from_station_name\",\"to_station_name\",\"from_station_id\",\"to_station_id\",\"usertype\",\"gender\",\"birthyear\"\n",
      " \n",
      "\n",
      "431,\"10/13/2014 10:31\",\"10/13/2014 10:48\",\"SEA00298\",985.935,\"2nd Ave & Spring St\",\"Occidental Park / Occidental Ave S & S Washington St\",\"CBD-06\",\"PS-04\",\"Member\",\"Male\",1960\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('cycle_share/trip.csv') as f:\n",
    "    lines = f.readlines()\n",
    "for l in lines[50793:50795]:\n",
    "    print(l, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines[50793].split(',')), len(lines[50794].split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"trip_id\"',\n",
       " '\"starttime\"',\n",
       " '\"stoptime\"',\n",
       " '\"bikeid\"',\n",
       " '\"tripduration\"',\n",
       " '\"from_station_name\"',\n",
       " '\"to_station_name\"',\n",
       " '\"from_station_id\"',\n",
       " '\"to_station_id\"',\n",
       " '\"usertype\"',\n",
       " '\"gender\"',\n",
       " '\"birthyear\"\\n']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0].split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_line = lines[50793]\n",
    "bad_toks = bad_line.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['59000',\n",
       " '\"4/17/2015 14:21\"',\n",
       " '\"4/17/2015 19:21\"',\n",
       " '\"SEA00362\"',\n",
       " '17990.668',\n",
       " '\"6th Ave S & S King St\"',\n",
       " '\"Westlake Ave & 6th Ave\"',\n",
       " '\"ID-04\"',\n",
       " '\"SLU-15\"trip_id\"',\n",
       " '\"starttime\"',\n",
       " '\"stoptime\"',\n",
       " '\"bikeid\"',\n",
       " '\"tripduration\"',\n",
       " '\"from_station_name\"',\n",
       " '\"to_station_name\"',\n",
       " '\"from_station_id\"',\n",
       " '\"to_station_id\"',\n",
       " '\"usertype\"',\n",
       " '\"gender\"',\n",
       " '\"birthyear\"\\n']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['59000',\n",
       " '\"4/17/2015 14:21\"',\n",
       " '\"4/17/2015 19:21\"',\n",
       " '\"SEA00362\"',\n",
       " '17990.668',\n",
       " '\"6th Ave S & S King St\"',\n",
       " '\"Westlake Ave & 6th Ave\"',\n",
       " '\"ID-04\"',\n",
       " '\"SLU-15\"trip_id\"']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_toks = bad_toks[:9]\n",
    "new_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"SLU-15\"'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end = new_toks[-1]\n",
    "end = '\"' + end.split('\"')[1] + '\"'\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'59000,\"4/17/2015 14:21\",\"4/17/2015 19:21\",\"SEA00362\",17990.668,\"6th Ave S & S King St\",\"Westlake Ave & 6th Ave\",\"ID-04\",\"SLU-15\",\"SLU-15\",\"SLU-15\",,,\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_toks[-1] = end\n",
    "new_toks.append(2*',' + '\\n')\n",
    "new_line = ','.join(new_toks)\n",
    "new_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_line.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines[50793] = new_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('cycle_share/trip_fixed.csv', 'w') as f:\n",
    "    for l in lines:\n",
    "        f.write(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File : trip_fixed.csv\n",
      "\n",
      "Error tokenizing data. C error: Expected 12 fields in line 50794, saw 14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "\n",
    "files = listdir('cycle_share')\n",
    "data = {}\n",
    "for f in files:\n",
    "    if f != 'trip.csv':\n",
    "        k = f.split('.')[0]  # remove .csv\n",
    "        path = 'cycle_share/' + f\n",
    "        try:\n",
    "            if k == 'trip_fixed':\n",
    "                k = 'trip'\n",
    "            data[k] = pd.read_csv(path)\n",
    "        except Exception as e:\n",
    "            print('File : {}\\n'.format(f))\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Print data summaries including the number of null values. Should we drop or try to correct any of the null values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATION \n",
      "\n",
      "Null counts\n",
      "station_id            0\n",
      "name                  0\n",
      "lat                   0\n",
      "long                  0\n",
      "install_date          0\n",
      "install_dockcount     0\n",
      "modification_date    41\n",
      "current_dockcount     0\n",
      "decommission_date    54\n",
      "dtype: int64 \n",
      "\n",
      "                   count        mean       std         min         25%  \\\n",
      "lat                 58.0   47.624796  0.019066   47.598488   47.613239   \n",
      "long                58.0 -122.327242  0.014957 -122.355230 -122.338735   \n",
      "install_dockcount   58.0   17.586207  3.060985   12.000000   16.000000   \n",
      "current_dockcount   58.0   16.517241  5.117021    0.000000   16.000000   \n",
      "\n",
      "                          50%         75%         max  \n",
      "lat                 47.618591   47.627712   47.666145  \n",
      "long              -122.328207 -122.316691 -122.284119  \n",
      "install_dockcount   18.000000   18.000000   30.000000  \n",
      "current_dockcount   18.000000   18.000000   26.000000   \n",
      "\n",
      "                  count unique                 top freq\n",
      "station_id           58     58               UW-02    1\n",
      "name                 58     58  Union St & 4th Ave    1\n",
      "install_date         58      9          10/13/2014   50\n",
      "modification_date    17     12           2/20/2015    4\n",
      "decommission_date     4      4            7/2/2016    1 \n",
      " -------------------------------------------------- \n",
      "\n",
      "WEATHER \n",
      "\n",
      "Null counts\n",
      "Date                            0\n",
      "Max_Temperature_F               0\n",
      "Mean_Temperature_F              1\n",
      "Min_TemperatureF                0\n",
      "Max_Dew_Point_F                 0\n",
      "MeanDew_Point_F                 0\n",
      "Min_Dewpoint_F                  0\n",
      "Max_Humidity                    0\n",
      "Mean_Humidity                   0\n",
      "Min_Humidity                    0\n",
      "Max_Sea_Level_Pressure_In       0\n",
      "Mean_Sea_Level_Pressure_In      0\n",
      "Min_Sea_Level_Pressure_In       0\n",
      "Max_Visibility_Miles            0\n",
      "Mean_Visibility_Miles           0\n",
      "Min_Visibility_Miles            0\n",
      "Max_Wind_Speed_MPH              0\n",
      "Mean_Wind_Speed_MPH             0\n",
      "Max_Gust_Speed_MPH            185\n",
      "Precipitation_In                0\n",
      "Events                        361\n",
      "dtype: int64 \n",
      "\n",
      "                            count       mean        std    min    25%    50%  \\\n",
      "Max_Temperature_F           689.0  64.027576  12.427843  39.00  55.00  63.00   \n",
      "Mean_Temperature_F          688.0  56.584302  10.408058  33.00  48.00  56.00   \n",
      "Min_TemperatureF            689.0  49.454282   9.451437  23.00  43.00  50.00   \n",
      "Max_Dew_Point_F             689.0  48.571843   7.501230  10.00  44.00  50.00   \n",
      "MeanDew_Point_F             689.0  45.021771   7.914025   4.00  41.00  46.00   \n",
      "Min_Dewpoint_F              689.0  40.873730   8.854608   1.00  36.00  42.00   \n",
      "Max_Humidity                689.0  84.541364   9.718948  40.00  78.00  86.00   \n",
      "Mean_Humidity               689.0  68.506531  12.701871  24.00  60.00  70.00   \n",
      "Min_Humidity                689.0  49.973875  15.825701  15.00  38.00  50.00   \n",
      "Max_Sea_Level_Pressure_In   689.0  30.121742   0.183367  29.47  30.01  30.12   \n",
      "Mean_Sea_Level_Pressure_In  689.0  30.034761   0.197503  29.31  29.93  30.04   \n",
      "Min_Sea_Level_Pressure_In   689.0  29.940610   0.221803  29.14  29.84  29.96   \n",
      "Max_Visibility_Miles        689.0   9.989840   0.266679   3.00  10.00  10.00   \n",
      "Mean_Visibility_Miles       689.0   9.429608   1.174360   1.00   9.00  10.00   \n",
      "Min_Visibility_Miles        689.0   7.245283   3.281278   0.00   4.00   9.00   \n",
      "Max_Wind_Speed_MPH          689.0  11.085631   3.921087   4.00   8.00  10.00   \n",
      "Mean_Wind_Speed_MPH         689.0   4.631350   2.780320   0.00   3.00   4.00   \n",
      "Precipitation_In            689.0   0.105065   0.235644   0.00   0.00   0.00   \n",
      "\n",
      "                              75%     max  \n",
      "Max_Temperature_F           73.00   98.00  \n",
      "Mean_Temperature_F          65.00   83.00  \n",
      "Min_TemperatureF            57.00   70.00  \n",
      "Max_Dew_Point_F             54.00   77.00  \n",
      "MeanDew_Point_F             51.00   59.00  \n",
      "Min_Dewpoint_F              47.00   57.00  \n",
      "Max_Humidity                90.00  100.00  \n",
      "Mean_Humidity               79.00   95.00  \n",
      "Min_Humidity                63.00   87.00  \n",
      "Max_Sea_Level_Pressure_In   30.24   30.86  \n",
      "Mean_Sea_Level_Pressure_In  30.16   30.81  \n",
      "Min_Sea_Level_Pressure_In   30.08   30.75  \n",
      "Max_Visibility_Miles        10.00   10.00  \n",
      "Mean_Visibility_Miles       10.00   10.00  \n",
      "Min_Visibility_Miles        10.00   10.00  \n",
      "Max_Wind_Speed_MPH          13.00   30.00  \n",
      "Mean_Wind_Speed_MPH          6.00   23.00  \n",
      "Precipitation_In             0.09    2.20   \n",
      "\n",
      "                   count unique       top freq\n",
      "Date                 689    689  1/8/2015    1\n",
      "Max_Gust_Speed_MPH   504     25         -  225\n",
      "Events               328      9      Rain  287 \n",
      " -------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in data.keys():\n",
    "    print(k.upper(), '\\n')\n",
    "    print('Null counts')\n",
    "    print(data[k].isnull().sum(), '\\n')\n",
    "    print(data[k].describe().T, '\\n')\n",
    "    print(data[k].describe(include=['O']).T, '\\n', 50*'-', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['weather'].Mean_Temperature_F.fillna(method='ffill', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a column in the trip table that contains only the date (no time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['station', 'weather'])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Merge weather data with trip data and be sure not to lose any trip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'trip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-df356c828cd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'trip'"
     ]
    }
   ],
   "source": [
    "data['trip']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Drop records that are completely duplicated (all values). Check for and inspect any duplicate trip_id values that remain. Remove if they exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create columns for lat & long values for the from- and to- stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Write a function to round all `tripduration` values to the nearest half second increment and then round all the values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Verify that `trip_duration` matches the timestamps to within 60 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.Something is wrong with the `Max_Gust_Speed_MPH` column. Identify and correct the problem, then save the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning: Movies\n",
    "\n",
    "This data set contains 28 attributes related to various movie titles that have been scraped from IMDb. The set is supposed to contain unique titles for each record, where each record has the following attributes:\n",
    "\n",
    "\"movie_title\" \"color\" \"num_critic_for_reviews\" \"movie_facebook_likes\" \"duration\" \"director_name\" \"director_facebook_likes\" \"actor_3_name\" \"actor_3_facebook_likes\" \"actor_2_name\" \"actor_2_facebook_likes\" \"actor_1_name\" \"actor_1_facebook_likes\" \"gross\" \"genres\" \"num_voted_users\" \"cast_total_facebook_likes\" \"facenumber_in_poster\" \"plot_keywords\" \"movie_imdb_link\" \"num_user_for_reviews\" \"language\" \"country\" \"content_rating\" \"budget\" \"title_year\" \"imdb_score\" \"aspect_ratio\"\n",
    "\n",
    "The original set is available kaggle ([here](https://www.kaggle.com/deepmatrix/imdb-5000-movie-dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check for and correct similar values in `color`, `language`,  and `country`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series\n",
    "from pandas import DataFrame as DF\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('movies/movies_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5043 entries, 0 to 5042\n",
      "Data columns (total 28 columns):\n",
      "color                        5024 non-null object\n",
      "director_name                4939 non-null object\n",
      "num_critic_for_reviews       4993 non-null float64\n",
      "duration                     5028 non-null float64\n",
      "director_facebook_likes      4939 non-null float64\n",
      "actor_3_facebook_likes       5020 non-null float64\n",
      "actor_2_name                 5030 non-null object\n",
      "actor_1_facebook_likes       5036 non-null float64\n",
      "gross                        4159 non-null float64\n",
      "genres                       5043 non-null object\n",
      "actor_1_name                 5036 non-null object\n",
      "movie_title                  5043 non-null object\n",
      "num_voted_users              5043 non-null int64\n",
      "cast_total_facebook_likes    5043 non-null int64\n",
      "actor_3_name                 5020 non-null object\n",
      "facenumber_in_poster         5030 non-null float64\n",
      "plot_keywords                4890 non-null object\n",
      "movie_imdb_link              5043 non-null object\n",
      "num_user_for_reviews         5022 non-null float64\n",
      "language                     5031 non-null object\n",
      "country                      5038 non-null object\n",
      "content_rating               4740 non-null object\n",
      "budget                       4551 non-null float64\n",
      "title_year                   4935 non-null float64\n",
      "actor_2_facebook_likes       5030 non-null float64\n",
      "imdb_score                   5043 non-null float64\n",
      "aspect_ratio                 4714 non-null float64\n",
      "movie_facebook_likes         5043 non-null int64\n",
      "dtypes: float64(13), int64(3), object(12)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color /n\n",
      "Black and White     206\n",
      "Color              4799\n",
      "black and white       3\n",
      "color                16\n",
      "Name: color, dtype: int64 \n",
      "\n",
      "\n",
      "language /n\n",
      "Aboriginal       2\n",
      "Arabic           5\n",
      "Aramaic          1\n",
      "Bosnian          1\n",
      "Cantonese       11\n",
      "Chinese          3\n",
      "Czech            1\n",
      "Danish           5\n",
      "Dari             2\n",
      "Dutch            4\n",
      "Dzongkha         1\n",
      "English       4704\n",
      "Filipino         1\n",
      "French          73\n",
      "German          19\n",
      "Greek            1\n",
      "Hebrew           5\n",
      "Hindi           28\n",
      "Hungarian        1\n",
      "Icelandic        2\n",
      "Indonesian       2\n",
      "Italian         11\n",
      "Japanese        18\n",
      "Kannada          1\n",
      "Kazakh           1\n",
      "Korean           8\n",
      "Mandarin        26\n",
      "Maya             1\n",
      "Mongolian        1\n",
      "None             2\n",
      "Norwegian        4\n",
      "Panjabi          1\n",
      "Persian          4\n",
      "Polish           4\n",
      "Portuguese       8\n",
      "Romanian         2\n",
      "Russian         11\n",
      "Slovenian        1\n",
      "Spanish         40\n",
      "Swahili          1\n",
      "Swedish          5\n",
      "Tamil            1\n",
      "Telugu           1\n",
      "Thai             3\n",
      "Urdu             1\n",
      "Vietnamese       1\n",
      "Zulu             2\n",
      "Name: language, dtype: int64 \n",
      "\n",
      "\n",
      "country /n\n",
      "Afghanistan                1\n",
      "Argentina                  4\n",
      "Aruba                      1\n",
      "Australia                 55\n",
      "Bahamas                    1\n",
      "Belgium                    4\n",
      "Brazil                     8\n",
      "Bulgaria                   1\n",
      "Cambodia                   1\n",
      "Cameroon                   1\n",
      "Canada                   126\n",
      "Chile                      1\n",
      "China                     30\n",
      "Colombia                   1\n",
      "Czech Republic             3\n",
      "Denmark                   11\n",
      "Dominican Republic         1\n",
      "Egypt                      1\n",
      "Finland                    1\n",
      "France                   154\n",
      "Georgia                    1\n",
      "Germany                   97\n",
      "Greece                     2\n",
      "Hong Kong                 17\n",
      "Hungary                    2\n",
      "Iceland                    3\n",
      "India                     34\n",
      "Indonesia                  1\n",
      "Iran                       4\n",
      "Ireland                   12\n",
      "                        ... \n",
      "Libya                      1\n",
      "Mexico                    17\n",
      "Netherlands                5\n",
      "New Line                   1\n",
      "New Zealand               15\n",
      "Nigeria                    1\n",
      "Norway                     8\n",
      "Official site              1\n",
      "Pakistan                   1\n",
      "Panama                     1\n",
      "Peru                       1\n",
      "Philippines                1\n",
      "Poland                     5\n",
      "Romania                    4\n",
      "Russia                    11\n",
      "Slovakia                   1\n",
      "Slovenia                   1\n",
      "South Africa               8\n",
      "South Korea               14\n",
      "Soviet Union               1\n",
      "Spain                     33\n",
      "Sweden                     6\n",
      "Switzerland                3\n",
      "Taiwan                     2\n",
      "Thailand                   5\n",
      "Turkey                     1\n",
      "UK                       448\n",
      "USA                     3807\n",
      "United Arab Emirates       1\n",
      "West Germany               3\n",
      "Name: country, Length: 65, dtype: int64 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in ['color', 'language', 'country']:\n",
    "    print(col, '/n')\n",
    "    print(movies[col].value_counts().sort_index(), '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Color              4815\n",
       "Black and White     209\n",
       "Name: color, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.loc[(movies.color == 'color'), 'color'] = 'Color'\n",
    "movies.loc[(movies.color == 'black and white'), 'color'] = 'Black and White'\n",
    "movies.color.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a function that detects and lists non-numeric columns containing values with leading or trailing whitespace. Remove the whitespace in these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_white(data, cols):\n",
    "    white_list = []\n",
    "    for col in cols:\n",
    "        for x in data[col]:\n",
    "            try:\n",
    "                l = x.split(' ')\n",
    "                if (l[0] == '') | (l[-1] == ''):\n",
    "                    print('{} has whitespace'.format(col))\n",
    "                    white_list.append(col)\n",
    "                    break\n",
    "            except Exception:\n",
    "                continue\n",
    "    return white_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "director_name has whitespace\n",
      "actor_2_name has whitespace\n",
      "movie_title has whitespace\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['director_name', 'actor_2_name', 'movie_title']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_cols = movies.select_dtypes(include = ['O']).columns\n",
    "white_list = has_white(movies, str_cols)\n",
    "white_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies[white_list] = movies[white_list].apply(lambda x: x.str.strip())\n",
    "has_white(movies, str_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Remove duplicate records. Inspect any remaining duplicate movie titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5043, 28)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4998, 28)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.drop_duplicates(inplace = True)\n",
    "movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4916, 4998)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.movie_title.nunique(), len(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4916.000000\n",
       "mean        1.016680\n",
       "std         0.132763\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         1.000000\n",
       "max         3.000000\n",
       "Name: movie_title, dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.movie_title.value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Ben-Hur', 'King Kong', 'Home', 'Syriana', 'Lucky Number Slevin',\n",
       "       'Oz the Great and Powerful', 'Creepshow', 'The Lovers', 'RoboCop',\n",
       "       '20,000 Leagues Under the Sea', 'Pan', 'The Island', 'The Gift',\n",
       "       'Glory', 'Aloha', 'Conan the Barbarian', 'The Host', 'Sabotage', 'Juno',\n",
       "       'Halloween', 'Mercury Rising', 'Clash of the Titans', 'Day of the Dead',\n",
       "       'Dredd', 'House of Wax', 'The Astronaut's Wife', 'The Karate Kid',\n",
       "       'The Lovely Bones', 'Skyfall', 'Cinderella', 'Precious', 'Side Effects',\n",
       "       'Chasing Liberty', 'The Return of the Living Dead', 'The Dead Zone',\n",
       "       'The Fog', 'The Tourist', 'Point Break', 'Twilight',\n",
       "       'Victor Frankenstein', 'The Watch', 'The Day the Earth Stood Still',\n",
       "       'The Fast and the Furious', 'Out of the Blue',\n",
       "       'Dodgeball: A True Underdog Story', 'Spider-Man 3',\n",
       "       'Around the World in 80 Days', 'Jack Reacher', 'Unknown',\n",
       "       'Murder by Numbers', 'Carrie', 'The Last House on the Left',\n",
       "       'Casino Royale', 'Snitch', 'Heist', 'Poltergeist',\n",
       "       'Exodus: Gods and Kings', 'Disturbia', 'TRON: Legacy', 'The Unborn',\n",
       "       'The Texas Chain Saw Massacre', 'The Great Gatsby', 'Lolita',\n",
       "       'A Nightmare on Elm Street', 'The Omen', 'Ghostbusters', 'Brothers',\n",
       "       'Snakes on a Plane', 'Dawn of the Dead', 'Goosebumps', 'Dekalog',\n",
       "       'Across the Universe', 'Eddie the Eagle', 'The Gambler',\n",
       "       'Teenage Mutant Ninja Turtles', 'First Blood', 'Planet of the Apes',\n",
       "       'The Jungle Book', 'Alice in Wonderland'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_counts = movies.movie_title.value_counts()\n",
    "potential_dups = movie_counts[movie_counts > 1].index\n",
    "potential_dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a function that returns two arrays: one for titles that are truly duplicated, and  one for duplicated titles are not the same movie.\n",
    "* hint: do this by comparing the imdb link values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def movie_duplicates(movie, potential):\n",
    "    subset = ['movie_title', 'movie_imdb_link']\n",
    "    dup_mask = movies.duplicated(subset=subset)\n",
    "    duplicated = movies.loc[dup_mask].movie_title.unique()\n",
    "    not_duplicated = Series(potential)[~Series(potential).isin(duplicated)].values\n",
    "    return duplicated, not_duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The Host', 'The Dead Zone', 'Out of the Blue'], dtype=object)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup, not_dup = movie_duplicates(movies, potential_dups)\n",
    "not_dup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Alter the names of duplicate titles that are different movies so each is unique. Then drop all duplicate rows based on movie title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in not_dup:\n",
    "    for n, idx in enumerate(movies[movies.movie_title == m].index):\n",
    "        movies.loc[idx, 'movie_title'] = m + '_{}'.format(n)\n",
    "        \n",
    "movies.drop_duplicates(subset=['movie_title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The Core                        1\n",
       "Love in the Time of Monsters    1\n",
       "Florence Foster Jenkins         1\n",
       "Albert Nobbs                    1\n",
       "State of Play                   1\n",
       "Name: movie_title, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.movie_title.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create a series that ranks actors by proportion of movies they have appeared in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = DF(movies.actor_1_name.value_counts())\n",
    "a2 = DF(movies.actor_2_name.value_counts())\n",
    "a3 = DF(movies.actor_3_name.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_all = a1.merge(a2, how='outer', left_index = True, right_index=True)\\\n",
    "    .merge(a3, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Robert De Niro    0.010775\n",
       "Morgan Freeman    0.008742\n",
       "Bruce Willis      0.007725\n",
       "Matt Damon        0.007522\n",
       "Johnny Depp       0.007319\n",
       "dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_counts = a_all.sum(axis=1)\n",
    "actor_ranks = (actor_counts/len(movies)).sort_values(ascending=False)\n",
    "actor_ranks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create a table that contains the first and last years each actor appeared, and their length of history. Then include columns for the actors proportion and total number of movies.\n",
    "* length is number of years they have appeared in movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor_1_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50 Cent</th>\n",
       "      <td>2005.0</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A.J. Buckley</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aaliyah</th>\n",
       "      <td>2002.0</td>\n",
       "      <td>2002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aasif Mandvi</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>2008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abbie Cornish</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                first    last\n",
       "actor_1_name                 \n",
       "50 Cent        2005.0  2005.0\n",
       "A.J. Buckley   2015.0  2015.0\n",
       "Aaliyah        2002.0  2002.0\n",
       "Aasif Mandvi   2008.0  2008.0\n",
       "Abbie Cornish  2009.0  2012.0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1 = movies.groupby('actor_1_name')\n",
    "g2 = movies.groupby('actor_2_name')\n",
    "g3 = movies.groupby('actor_3_name')\n",
    "\n",
    "hists = {}\n",
    "for i, g in enumerate([g1, g2, g3]):\n",
    "    k = 'g{}'.format(i)\n",
    "    hists[k] = g.apply(lambda x: Series({'last': x['title_year'].max(),\n",
    "                                        'first': x['title_year'].min()}))\n",
    "hists['g0'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Laurence Olivier</th>\n",
       "      <td>1940.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Debbie Reynolds</th>\n",
       "      <td>1952.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marlon Brando</th>\n",
       "      <td>1951.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dean Stockwell</th>\n",
       "      <td>1947.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Robert Duvall</th>\n",
       "      <td>1962.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   first    last  years\n",
       "Laurence Olivier  1940.0  2004.0   64.0\n",
       "Debbie Reynolds   1952.0  2012.0   60.0\n",
       "Marlon Brando     1951.0  2006.0   55.0\n",
       "Dean Stockwell    1947.0  2001.0   54.0\n",
       "Robert Duvall     1962.0  2014.0   52.0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = hists['g0'].merge(hists['g1'], how='outer', left_index=True, right_index=True)\\\n",
    "    .merge(hists['g2'], how = 'outer', left_index=True, right_index=True)\n",
    "actor_hist = history.apply(lambda r: Series({'first': r.min(),\n",
    "                                            'last':r.max(),\n",
    "                                            'years':r.max() - r.min()}),\n",
    "                     \\\n",
    "                           ]]]'axis = 1).sort_values(by='years', ascending=False)\n",
    "actor_hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>years</th>\n",
       "      <th>movie_prop</th>\n",
       "      <th>movie_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Laurence Olivier</th>\n",
       "      <td>1940.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Debbie Reynolds</th>\n",
       "      <td>1952.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marlon Brando</th>\n",
       "      <td>1951.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dean Stockwell</th>\n",
       "      <td>1947.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Robert Duvall</th>\n",
       "      <td>1962.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.004879</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   first    last  years  movie_prop  movie_count\n",
       "Laurence Olivier  1940.0  2004.0   64.0    0.001016          5.0\n",
       "Debbie Reynolds   1952.0  2012.0   60.0    0.000813          4.0\n",
       "Marlon Brando     1951.0  2006.0   55.0    0.001830          9.0\n",
       "Dean Stockwell    1947.0  2001.0   54.0    0.001016          5.0\n",
       "Robert Duvall     1962.0  2014.0   52.0    0.004879         24.0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_hist['movie_prop'] = actor_ranks\n",
    "actor_hist['movie_count'] = round(actor_ranks*len(movies))\n",
    "actor_hist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create a column that gives each movie an integer ranking based on gross sales\n",
    "* 1 should indicate the highest gross\n",
    "* If more than one movie has equal sales, assign all the lowest rank in the group\n",
    "* The next rank after this group should increase only by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     a\n",
      "0  4.0\n",
      "1  3.0\n",
      "2  2.0\n",
      "3  4.0\n",
      "4  3.0\n",
      "5  1.0\n",
      "     a\n",
      "0  5.0\n",
      "1  3.0\n",
      "2  2.0\n",
      "3  5.0\n",
      "4  3.0\n",
      "5  1.0\n"
     ]
    }
   ],
   "source": [
    "df = DF({'a': [1,2,3,1,2,4]})\n",
    "dense_method = df.rank(ascending=False, method='dense')\n",
    "min_method = df.rank(ascending=False, method='min')\n",
    "print(dense_method)\n",
    "print(min_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['movie_sales_rank'] = movies.gross.rank(method='min', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gross</th>\n",
       "      <th>movie_sales_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>760505847.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>658672302.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>652177271.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>623279547.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>533316061.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          gross  movie_sales_rank\n",
       "0   760505847.0               1.0\n",
       "26  658672302.0               2.0\n",
       "29  652177271.0               3.0\n",
       "17  623279547.0               4.0\n",
       "66  533316061.0               5.0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies[['gross', 'movie_sales_rank']].sort_values(by='gross', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
